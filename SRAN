
<table><tr><td bgcolor=#D1EEEE><center><font size='8'>Image Super-Resolution Using Deep Convolutional Networks</font></center>
<center><font size='4'><br/>Zhenxing Huang, Jincai Chen, Ping Lu, Zhanli Hu</font></center>
<center><font size='4'><br/>National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan, China</font></center>
<center><font size='4'>Key Laboratory of Information Storage System (School of Computer Science and Technology, Huazhong University of Science and Technology</font></center>
<center><font size='4'> Shenzhen Institutes of Advanced Technology,Chinese Academy of Sciences,Shenzhen,China</font></center></td></tr></table>

#Materials
Paper: 

Code:

Results:

#Abstract 
Convolution neural network (CNN) has been largely
applied to learn the mapping function between low resolution
(LR) images and high resolution (HR) ones, which has made
great progress in single image super resolution (SISR) domain.
With the aid of deeper networks through cascading collaborative
blocks, several works has improve image quality effectively.
In these works, the local cascading block are usually treated
as an atomic term to extend, which is a convenient way to
construct deep structures to extract feature and fuse information.
However, this would primarily limit the representation of the
latter reconstruction layer for its lack of abundant features if
the local atomic block could output only one type information.
For instance, the residual block could only contain residual
information.

In this paper, we propose separable mechanism in network
designing for multi-streams output to increase the representation
capability of neural networks. In sake for diversity of features,
we design four separable residual attention blocks to obtain
two-stream outputs, which ultimately combine low-level features
and high-level convolution layers. Similar to residual-in-residual
(RIR) structure, we propose attention-in-attention (AIA) mecha-
nism to deepen our networks. Experimental results demonstrate
the superiority of our method on several images datasets.

# Information Conduction Ways

# Separable Residual Attetnion Blocks


# Ablation Analysis


#Results
![img](https://github.com/huanggzx/SRAN/tree/master/images/Results_1.png)
![img](https://github.com/huanggzx/SRAN/tree/master/images/Results_2.png)

#Conclusion


#Citation
<code>
@InProceedings{wang2019edvr,  
&emsp;&emsp;&emsp;&emsp;         author = {Wang, Xintao and Chan, Kelvin C.K. and Yu, Ke and Dong, Chao and Loy, Chen Change},  
&emsp;&emsp;&emsp;&emsp;          title = {EDVR: Video Restoration with Enhanced Deformable Convolutional Networks},  
&emsp;&emsp;&emsp;&emsp;          booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},  
&emsp;&emsp;&emsp;&emsp;          month = {June},  
&emsp;&emsp;&emsp;&emsp;          year = {2019}  
          }
</code>


#Concat 
If you have any question, please contact Zhenxing Huang at **huangzx@hust.edu.cn**.
